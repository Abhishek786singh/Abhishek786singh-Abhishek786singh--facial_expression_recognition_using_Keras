{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/User/Desktop/ML hub/EXpression dataset/fer2013/fer2013.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sampling and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples distribution across Usage:\n",
      "Training       28709\n",
      "PrivateTest     3589\n",
      "PublicTest      3589\n",
      "Name: Usage, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Now lets see the samples distribution across different sample sets(training or test) and in the emotion classes.\n",
    "print('Samples distribution across Usage:')\n",
    "print(data.Usage.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples per emotion:\n",
      "3    8989\n",
      "6    6198\n",
      "4    6077\n",
      "2    5121\n",
      "0    4953\n",
      "5    4002\n",
      "1     547\n",
      "Name: emotion, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Samples per emotion:')\n",
    "print(data.emotion.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pixels for a sample:\n",
      "2304\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Number of pixels for a sample:')\n",
    "print(len(data.pixels[0].split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Firstly, dataset is categorzied into training, validation and test sets depending on the Usage value for the samples\n",
    "train_set = data[(data.Usage == 'Training')]\n",
    "validation_set = data[(data.Usage == 'PublicTest')]\n",
    "test_set = data[(data.Usage == 'PrivateTest')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_labels = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\n",
    "num_classes = len(emotion_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "depth = 1\n",
    "height = int(sqrt(len(data.pixels[0].split())))\n",
    "width = height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tensorenv\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=48x48 at 0x2AD897207F0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angry\n"
     ]
    }
   ],
   "source": [
    "## Now, lets visualize some of our data\n",
    "sample_number = 76 \n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from IPython.display import display\n",
    "\n",
    "array = np.mat(data.pixels[sample_number]).reshape(48,48)\n",
    "image = scipy.misc.toimage(array)\n",
    "display(image)\n",
    "print(emotion_labels[data.emotion[sample_number]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To form our input for the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#------------------------------\n",
    "#cpu - gpu configuration\n",
    "config = tf.ConfigProto( device_count = {'GPU': 0 , 'CPU': 56} ) #max: 1 gpu, 56 cpu\n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)\n",
    "#------------------------------\n",
    "#variables\n",
    "num_classes = 7 #angry, disgust, fear, happy, sad, surprise, neutral\n",
    "batch_size = 256\n",
    "epochs = 25\n",
    "with open(\"C:/Users/User/Desktop/ML hub/EXpression dataset/fer2013/fer2013.csv\"\") as f:\n",
    "  content = f.readlines()\n",
    "\n",
    "lines = np.array(content)\n",
    "\n",
    "num_of_instances = lines.size\n",
    "print(\"number of instances: \",num_of_instances)\n",
    "print(\"instance length: \",len(lines[1].split(\",\")[1].split(\" \")))\n",
    "\n",
    "x_train, y_train, x_test, y_test = [], [], [], []\n",
    "\n",
    "for i in range(1,num_of_instances):\n",
    "    try:\n",
    "        emotion, img, usage = lines[i].split(\",\")\n",
    "          \n",
    "        val = img.split(\" \")\n",
    "            \n",
    "        pixels = np.array(val, 'float32')\n",
    "        \n",
    "        emotion = keras.utils.to_categorical(emotion, num_classes)\n",
    "    \n",
    "        if 'Training' in usage:\n",
    "            y_train.append(emotion)\n",
    "            x_train.append(pixels)\n",
    "        elif 'PublicTest' in usage:\n",
    "            y_test.append(emotion)\n",
    "            x_test.append(pixels)\n",
    "    except:\n",
    "      print(\"\", end=\"\")\n",
    "\n",
    "#------------------------------\n",
    "#data transformation for train and test sets\n",
    "x_train = np.array(x_train, 'float32')\n",
    "y_train = np.array(y_train, 'float32')\n",
    "x_test = np.array(x_test, 'float32')\n",
    "y_test = np.array(y_test, 'float32')\n",
    "\n",
    "x_train /= 255 #normalize inputs between [0, 1]\n",
    "x_test /= 255\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 48, 48, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], 48, 48, 1)\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "#------------------------------\n",
    "#construct CNN structure\n",
    "model = Sequential()\n",
    "\n",
    "#1st convolution layer\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n",
    "\n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "#------------------------------\n",
    "#batch process\n",
    "gen = ImageDataGenerator()\n",
    "train_generator = gen.flow(x_train, y_train, batch_size=batch_size)\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "model.compile(loss='categorical_crossentropy'\n",
    "    , optimizer=keras.optimizers.Adam()\n",
    "    , metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "fit = True\n",
    "\n",
    "if fit == True:\n",
    "\t#model.fit_generator(x_train, y_train, epochs=epochs) #train for all trainset\n",
    "\tmodel.fit_generator(train_generator, steps_per_epoch=batch_size, epochs=epochs) #train for randomly selected one\n",
    "else:\n",
    "\tmodel.load_weights('C:/Users/User/Desktop/ML hub') #load weights\n",
    "\t\n",
    "#------------------------------\n",
    "\"\"\"\n",
    "#overall evaluation\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', 100*score[1])\n",
    "\"\"\"\n",
    "\n",
    "def emotion_analysis(emotions):\n",
    "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "    y_pos = np.arange(len(objects))\n",
    "    \n",
    "    plt.bar(y_pos, emotions, align='center', alpha=0.5)\n",
    "    plt.xticks(y_pos, objects)\n",
    "    plt.ylabel('percentage')\n",
    "    plt.title('emotion')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model25.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Evaluation\n",
    "train_score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Train loss:', train_score[0])\n",
    "print('Train accuracy:', 100*train_score[1])\n",
    " \n",
    "test_score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', test_score[0])\n",
    "print('Test accuracy:', 100*test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix.\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    " \n",
    "pred_list = []; actual_list = []\n",
    " \n",
    "for i in predictions:\n",
    " \n",
    "  pred_list.append(np.argmax(i))\n",
    "for i in y_test:\n",
    "    actual_list.append(np.argmax(i))\n",
    "confusion_matrix(actual_list, pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_testset_results = True\n",
    "\n",
    "if monitor_testset_results == True:\n",
    "\t# predictions for test dataset\n",
    "\tpredictions = model.predict(x_test)\n",
    "\n",
    "\tindex = 0\n",
    "\tfor i in predictions:\n",
    "\t\tif index < 30 and index >= 20:\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\t\ttesting_img = np.array(x_test[index], 'float32')\n",
    "\t\t\ttesting_img = testing_img.reshape([48, 48]);\n",
    "\t\t\t\n",
    "\t\t\tplt.gray()\n",
    "\t\t\tplt.imshow(testing_img)\n",
    "\t\t\tplt.show()\n",
    "\t\t\tprint(i)\n",
    "            emotion_analysis(i)\n",
    "\t\t\tprint(\"----------------------------------------------\")\n",
    "\t\tindex = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model25.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def emotion_analysis(emotions):\n",
    "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "    y_pos = np.arange(len(objects))\n",
    "    \n",
    "    plt.bar(y_pos, emotions, align='center', alpha=0.5)\n",
    "    plt.xticks(y_pos, objects)\n",
    "    plt.ylabel('percentage')\n",
    "    plt.title('emotion')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Testing a file.\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "file = 'photo.jpg'\n",
    "true_image = image.load_img(file)\n",
    "img = image.load_img(file, grayscale=True, target_size=(48, 48))\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "\n",
    "x /= 255\n",
    "\n",
    "custom = model.predict(x)\n",
    "emotion_analysis(custom[0])\n",
    "\n",
    "x = np.array(x, 'float32')\n",
    "x = x.reshape([48, 48]);\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(true_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "            \n",
    "def facecrop(image):  \n",
    "    facedata = \"C:/Users/User/Desktop/ML hub/Computer vision/haarcascade_frontalface_default.xml\"\n",
    "    cascade = cv2.CascadeClassifier(facedata)\n",
    "\n",
    "    img = cv2.imread(image)\n",
    "\n",
    "    try:\n",
    "    \n",
    "        minisize = (img.shape[1],img.shape[0])\n",
    "        miniframe = cv2.resize(img, minisize)\n",
    "\n",
    "        faces = cascade.detectMultiScale(miniframe)\n",
    "\n",
    "        for f in faces:\n",
    "            x, y, w, h = [ v for v in f ]\n",
    "            cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "\n",
    "            sub_face = img[y:y+h, x:x+w]\n",
    "\n",
    "            \n",
    "            cv2.imwrite('C:/Users/User/Desktop/ML hub/Computer vision/capture.jpg', sub_face)\n",
    "            #print (\"Writing: \" + image)\n",
    "\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "\n",
    "    #cv2.imshow(image, img)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    facecrop('1.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
